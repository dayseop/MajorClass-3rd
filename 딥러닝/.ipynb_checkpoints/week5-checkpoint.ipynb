{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5866fb4-6a10-4399-9ea4-7435e85f6e11",
   "metadata": {},
   "source": [
    "## 파이토치\n",
    "* 딥러닝 라이브러리가 아니였음\n",
    "* numpy는 gpu에 안올라감\n",
    "* 딥러닝이랑 잘 맞아서 딥러닝 라이브러리가 됨\n",
    "* 텐서 구글 파이 페이스북\n",
    "* 모든 기업에서 파이토치로 개발함\n",
    "* 텐서플로 잦은 업데이트와 문법으로 도태 됨\n",
    "* 동적프로그래밍이 가능함 : 실행 도중에 변수를 바꾸거나 새로운 입력 넣기가 가능함 (텐서플러1.0에선 불가)\n",
    "* 파이썬의 주요한 환경을 그대로 사용가능 함\n",
    "* 파이토치는 cuda 빠른 연산이 가능하다\n",
    "* 빠른 라이브러리 업데이트됨\n",
    "* 자동화됨 - 미분을 생각안해도 미분을 자동으로 해줌\n",
    "* 텐서라는 변수를 사용 함\n",
    "* 파이썬의 array나 list는 gpu 못올라가지만 텐서는 가능\n",
    "* 텐서들은 앞에 torch를 붙임 (자동으로 잡아줌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7496b15f-9969-46ce-83c9-8df572047515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f708c671-a526-4cf2-9c67-4e8806c38a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cee3c7-3ad3-4918-9a22-27ae9ee926a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "data_list = [1, 2, 3]\n",
    "data_array = np.array([1, 2, 3])\n",
    "data_tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(type(data_list))   ## 데이터 타입이 다르다\n",
    "print(type(data_array))\n",
    "print(type(data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca78920-a52c-4bf7-8222-394e7a1b0608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.tensor([1, 2, 3])    ## int\n",
    "print(data_tensor.dtype)\n",
    "\n",
    "data_tensor = torch.tensor([1., 2., 3.,]) ## float\n",
    "print(data_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91e233d-4522-4048-9328-3d439832d141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int32\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "float_tensor = torch.tensor([1, 2, 3], dtype = torch.float64)\n",
    "print(float_tensor.dtype)\n",
    "\n",
    "int_tensor = torch.tensor([1.1, 2.2, 3.8,], dtype = torch.int)\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac6fd81-74a4-49a8-804c-9f452ad4b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "convert_tensor = float_tensor.to(dtype = torch.float32)\n",
    "print(convert_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14b450e-724b-407c-8c09-719d087ef687",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_tensor = torch.tensor([1, 2, 3], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f6aed5-4107-42ef-bcf0-61fd28d0c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Myself, self).__init__() ## 필수항목 super는 부모 초기화, 필요한 네트워크 정의, 변수 정의)\n",
    "\n",
    "    def forward(self, x): ## 값이 들어오면 x로 처리하면 된다. \n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980188b0-6f91-4f2d-84ce-560d9ecee9d6",
   "metadata": {},
   "source": [
    "## 파이토치 모델\n",
    "* 모델(network) 구성과 관련된 것 torch.nn에 들어 있음\n",
    "* linear reg~ 도 네트워크임\n",
    "* nn.Linear(1,1) 앞이 input size, 뒤가 output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8bc708-1fa7-4038-a5ab-b367cd251c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "torch.Size([6, 1])\n",
      "tensor([[-1.3180],\n",
      "        [-2.0552],\n",
      "        [-2.7925],\n",
      "        [-3.5297],\n",
      "        [-4.2670],\n",
      "        [-5.0042]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.l1 = nn.Linear(1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = MyModel() ## 두번쨰 forward 실행 됨\n",
    "\n",
    "hours = torch.FloatTensor([2, 3, 4, 5, 6, 7])    ##[배치, 데이터크기] 배치 -> 메모리에 몇개 씩 올리는지 \n",
    "print(hours.shape)\n",
    "hours = hours.view(-1, 1)  ## [6,1] 올려줘야 함  reshape -> view로 사용하면 됨 \n",
    "print(hours.shape)\n",
    "\n",
    "print(model(hours)) ## w,b 설정안해도 초기화해서 랜덤으로 들어가서 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126e38a1-0914-44b0-8e08-70cfe104cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()  ## (x-y)^2의 평균\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01) ## parameter 학습시켜야 할 대상(w,b) (SGD -> Sto ~~ 원래는 다 넣고(-1, 1로 나오면 loss가 없는 것 처럼 보임), 데이터 섞어가면서 나눠서함), 기본보다 frequent 모델 파라미터를 업데이트, 메모리 덜 먹음, 데이터가 많아도 나눠서 하기 떄문에 시간이 덜걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfcca89a-f438-4ca4-b8b2-34f15e045832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100 / 10000], Loss: 50.2609\n",
      "Epoch [200 / 10000], Loss: 46.4202\n",
      "Epoch [300 / 10000], Loss: 44.0573\n",
      "Epoch [400 / 10000], Loss: 42.6036\n",
      "Epoch [500 / 10000], Loss: 41.7093\n",
      "Epoch [600 / 10000], Loss: 41.1591\n",
      "Epoch [700 / 10000], Loss: 40.8206\n",
      "Epoch [800 / 10000], Loss: 40.6123\n",
      "Epoch [900 / 10000], Loss: 40.4842\n",
      "Epoch [1000 / 10000], Loss: 40.4054\n",
      "Epoch [1100 / 10000], Loss: 40.3569\n",
      "Epoch [1200 / 10000], Loss: 40.3271\n",
      "Epoch [1300 / 10000], Loss: 40.3087\n",
      "Epoch [1400 / 10000], Loss: 40.2974\n",
      "Epoch [1500 / 10000], Loss: 40.2905\n",
      "Epoch [1600 / 10000], Loss: 40.2862\n",
      "Epoch [1700 / 10000], Loss: 40.2836\n",
      "Epoch [1800 / 10000], Loss: 40.2819\n",
      "Epoch [1900 / 10000], Loss: 40.2810\n",
      "Epoch [2000 / 10000], Loss: 40.2804\n",
      "Epoch [2100 / 10000], Loss: 40.2800\n",
      "Epoch [2200 / 10000], Loss: 40.2797\n",
      "Epoch [2300 / 10000], Loss: 40.2796\n",
      "Epoch [2400 / 10000], Loss: 40.2795\n",
      "Epoch [2500 / 10000], Loss: 40.2795\n",
      "Epoch [2600 / 10000], Loss: 40.2794\n",
      "Epoch [2700 / 10000], Loss: 40.2794\n",
      "Epoch [2800 / 10000], Loss: 40.2794\n",
      "Epoch [2900 / 10000], Loss: 40.2794\n",
      "Epoch [3000 / 10000], Loss: 40.2794\n",
      "Epoch [3100 / 10000], Loss: 40.2794\n",
      "Epoch [3200 / 10000], Loss: 40.2794\n",
      "Epoch [3300 / 10000], Loss: 40.2794\n",
      "Epoch [3400 / 10000], Loss: 40.2793\n",
      "Epoch [3500 / 10000], Loss: 40.2794\n",
      "Epoch [3600 / 10000], Loss: 40.2794\n",
      "Epoch [3700 / 10000], Loss: 40.2794\n",
      "Epoch [3800 / 10000], Loss: 40.2794\n",
      "Epoch [3900 / 10000], Loss: 40.2794\n",
      "Epoch [4000 / 10000], Loss: 40.2793\n",
      "Epoch [4100 / 10000], Loss: 40.2794\n",
      "Epoch [4200 / 10000], Loss: 40.2794\n",
      "Epoch [4300 / 10000], Loss: 40.2794\n",
      "Epoch [4400 / 10000], Loss: 40.2794\n",
      "Epoch [4500 / 10000], Loss: 40.2794\n",
      "Epoch [4600 / 10000], Loss: 40.2794\n",
      "Epoch [4700 / 10000], Loss: 40.2794\n",
      "Epoch [4800 / 10000], Loss: 40.2794\n",
      "Epoch [4900 / 10000], Loss: 40.2794\n",
      "Epoch [5000 / 10000], Loss: 40.2794\n",
      "Epoch [5100 / 10000], Loss: 40.2794\n",
      "Epoch [5200 / 10000], Loss: 40.2794\n",
      "Epoch [5300 / 10000], Loss: 40.2794\n",
      "Epoch [5400 / 10000], Loss: 40.2794\n",
      "Epoch [5500 / 10000], Loss: 40.2794\n",
      "Epoch [5600 / 10000], Loss: 40.2794\n",
      "Epoch [5700 / 10000], Loss: 40.2794\n",
      "Epoch [5800 / 10000], Loss: 40.2794\n",
      "Epoch [5900 / 10000], Loss: 40.2794\n",
      "Epoch [6000 / 10000], Loss: 40.2794\n",
      "Epoch [6100 / 10000], Loss: 40.2794\n",
      "Epoch [6200 / 10000], Loss: 40.2794\n",
      "Epoch [6300 / 10000], Loss: 40.2794\n",
      "Epoch [6400 / 10000], Loss: 40.2794\n",
      "Epoch [6500 / 10000], Loss: 40.2794\n",
      "Epoch [6600 / 10000], Loss: 40.2794\n",
      "Epoch [6700 / 10000], Loss: 40.2794\n",
      "Epoch [6800 / 10000], Loss: 40.2794\n",
      "Epoch [6900 / 10000], Loss: 40.2794\n",
      "Epoch [7000 / 10000], Loss: 40.2794\n",
      "Epoch [7100 / 10000], Loss: 40.2794\n",
      "Epoch [7200 / 10000], Loss: 40.2794\n",
      "Epoch [7300 / 10000], Loss: 40.2794\n",
      "Epoch [7400 / 10000], Loss: 40.2794\n",
      "Epoch [7500 / 10000], Loss: 40.2794\n",
      "Epoch [7600 / 10000], Loss: 40.2794\n",
      "Epoch [7700 / 10000], Loss: 40.2794\n",
      "Epoch [7800 / 10000], Loss: 40.2794\n",
      "Epoch [7900 / 10000], Loss: 40.2794\n",
      "Epoch [8000 / 10000], Loss: 40.2794\n",
      "Epoch [8100 / 10000], Loss: 40.2794\n",
      "Epoch [8200 / 10000], Loss: 40.2794\n",
      "Epoch [8300 / 10000], Loss: 40.2794\n",
      "Epoch [8400 / 10000], Loss: 40.2794\n",
      "Epoch [8500 / 10000], Loss: 40.2794\n",
      "Epoch [8600 / 10000], Loss: 40.2794\n",
      "Epoch [8700 / 10000], Loss: 40.2794\n",
      "Epoch [8800 / 10000], Loss: 40.2794\n",
      "Epoch [8900 / 10000], Loss: 40.2794\n",
      "Epoch [9000 / 10000], Loss: 40.2794\n",
      "Epoch [9100 / 10000], Loss: 40.2794\n",
      "Epoch [9200 / 10000], Loss: 40.2794\n",
      "Epoch [9300 / 10000], Loss: 40.2794\n",
      "Epoch [9400 / 10000], Loss: 40.2794\n",
      "Epoch [9500 / 10000], Loss: 40.2794\n",
      "Epoch [9600 / 10000], Loss: 40.2794\n",
      "Epoch [9700 / 10000], Loss: 40.2794\n",
      "Epoch [9800 / 10000], Loss: 40.2794\n",
      "Epoch [9900 / 10000], Loss: 40.2794\n",
      "Epoch [10000 / 10000], Loss: 40.2794\n"
     ]
    }
   ],
   "source": [
    "h = np.array([2, 3, 4, 5, 6, 7])\n",
    "s = np.array([25, 49, 42, 57, 72, 68])\n",
    "\n",
    "hours = torch.FloatTensor(h).view(-1,1)\n",
    "score = torch.FloatTensor(s).view(-1,1)\n",
    "\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(hours)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, score)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if(epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1} / {num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5844911f-fb2a-4b07-811a-50a3caca3628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h, s, 'o')\n",
    "\n",
    "x = torch.linspace(0, 10, 10)\n",
    "predict = model(x.view(-1, 1))\n",
    "predict = predict.detach().numpy() ## detach -> 원래 자동미분기가 있는데 없애고 텐서로 바꾸고 돌림\n",
    "plt.plot(x.numpy(), predict, 'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05de9a4-0951-4e1a-b08d-41a92c4d8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9999],\n",
      "        [0.9981],\n",
      "        [0.9892],\n",
      "        [0.9741]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.l1 = nn.Linear(1,1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "model = MyModel() ## 두번쨰 forward 실행 됨\n",
    "\n",
    "hours = torch.FloatTensor([10, 7, 5, 4]).view(-1,1)    ##[배치, 데이터크기] 배치 -> 메모리에 몇개 씩 올리는지 \n",
    "\n",
    "print(model(hours)) ## w,b 설정안해도 초기화해서 랜덤으로 들어가서 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f57bb0e3-5b68-4255-bb00-15bc7a3d3514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/20000], Loss: 0.5634\n",
      "Epoch [200/20000], Loss: 0.4998\n",
      "Epoch [300/20000], Loss: 0.4494\n",
      "Epoch [400/20000], Loss: 0.4089\n",
      "Epoch [500/20000], Loss: 0.3758\n",
      "Epoch [600/20000], Loss: 0.3483\n",
      "Epoch [700/20000], Loss: 0.3252\n",
      "Epoch [800/20000], Loss: 0.3054\n",
      "Epoch [900/20000], Loss: 0.2883\n",
      "Epoch [1000/20000], Loss: 0.2734\n",
      "Epoch [1100/20000], Loss: 0.2603\n",
      "Epoch [1200/20000], Loss: 0.2485\n",
      "Epoch [1300/20000], Loss: 0.2380\n",
      "Epoch [1400/20000], Loss: 0.2285\n",
      "Epoch [1500/20000], Loss: 0.2198\n",
      "Epoch [1600/20000], Loss: 0.2119\n",
      "Epoch [1700/20000], Loss: 0.2047\n",
      "Epoch [1800/20000], Loss: 0.1979\n",
      "Epoch [1900/20000], Loss: 0.1917\n",
      "Epoch [2000/20000], Loss: 0.1859\n",
      "Epoch [2100/20000], Loss: 0.1805\n",
      "Epoch [2200/20000], Loss: 0.1755\n",
      "Epoch [2300/20000], Loss: 0.1707\n",
      "Epoch [2400/20000], Loss: 0.1663\n",
      "Epoch [2500/20000], Loss: 0.1621\n",
      "Epoch [2600/20000], Loss: 0.1581\n",
      "Epoch [2700/20000], Loss: 0.1543\n",
      "Epoch [2800/20000], Loss: 0.1508\n",
      "Epoch [2900/20000], Loss: 0.1474\n",
      "Epoch [3000/20000], Loss: 0.1441\n",
      "Epoch [3100/20000], Loss: 0.1411\n",
      "Epoch [3200/20000], Loss: 0.1381\n",
      "Epoch [3300/20000], Loss: 0.1353\n",
      "Epoch [3400/20000], Loss: 0.1326\n",
      "Epoch [3500/20000], Loss: 0.1301\n",
      "Epoch [3600/20000], Loss: 0.1276\n",
      "Epoch [3700/20000], Loss: 0.1252\n",
      "Epoch [3800/20000], Loss: 0.1229\n",
      "Epoch [3900/20000], Loss: 0.1207\n",
      "Epoch [4000/20000], Loss: 0.1186\n",
      "Epoch [4100/20000], Loss: 0.1166\n",
      "Epoch [4200/20000], Loss: 0.1146\n",
      "Epoch [4300/20000], Loss: 0.1128\n",
      "Epoch [4400/20000], Loss: 0.1109\n",
      "Epoch [4500/20000], Loss: 0.1092\n",
      "Epoch [4600/20000], Loss: 0.1075\n",
      "Epoch [4700/20000], Loss: 0.1058\n",
      "Epoch [4800/20000], Loss: 0.1042\n",
      "Epoch [4900/20000], Loss: 0.1027\n",
      "Epoch [5000/20000], Loss: 0.1012\n",
      "Epoch [5100/20000], Loss: 0.0997\n",
      "Epoch [5200/20000], Loss: 0.0983\n",
      "Epoch [5300/20000], Loss: 0.0969\n",
      "Epoch [5400/20000], Loss: 0.0956\n",
      "Epoch [5500/20000], Loss: 0.0943\n",
      "Epoch [5600/20000], Loss: 0.0931\n",
      "Epoch [5700/20000], Loss: 0.0918\n",
      "Epoch [5800/20000], Loss: 0.0906\n",
      "Epoch [5900/20000], Loss: 0.0895\n",
      "Epoch [6000/20000], Loss: 0.0884\n",
      "Epoch [6100/20000], Loss: 0.0873\n",
      "Epoch [6200/20000], Loss: 0.0862\n",
      "Epoch [6300/20000], Loss: 0.0851\n",
      "Epoch [6400/20000], Loss: 0.0841\n",
      "Epoch [6500/20000], Loss: 0.0831\n",
      "Epoch [6600/20000], Loss: 0.0822\n",
      "Epoch [6700/20000], Loss: 0.0812\n",
      "Epoch [6800/20000], Loss: 0.0803\n",
      "Epoch [6900/20000], Loss: 0.0794\n",
      "Epoch [7000/20000], Loss: 0.0785\n",
      "Epoch [7100/20000], Loss: 0.0777\n",
      "Epoch [7200/20000], Loss: 0.0768\n",
      "Epoch [7300/20000], Loss: 0.0760\n",
      "Epoch [7400/20000], Loss: 0.0752\n",
      "Epoch [7500/20000], Loss: 0.0744\n",
      "Epoch [7600/20000], Loss: 0.0736\n",
      "Epoch [7700/20000], Loss: 0.0729\n",
      "Epoch [7800/20000], Loss: 0.0721\n",
      "Epoch [7900/20000], Loss: 0.0714\n",
      "Epoch [8000/20000], Loss: 0.0707\n",
      "Epoch [8100/20000], Loss: 0.0700\n",
      "Epoch [8200/20000], Loss: 0.0693\n",
      "Epoch [8300/20000], Loss: 0.0687\n",
      "Epoch [8400/20000], Loss: 0.0680\n",
      "Epoch [8500/20000], Loss: 0.0674\n",
      "Epoch [8600/20000], Loss: 0.0667\n",
      "Epoch [8700/20000], Loss: 0.0661\n",
      "Epoch [8800/20000], Loss: 0.0655\n",
      "Epoch [8900/20000], Loss: 0.0649\n",
      "Epoch [9000/20000], Loss: 0.0643\n",
      "Epoch [9100/20000], Loss: 0.0638\n",
      "Epoch [9200/20000], Loss: 0.0632\n",
      "Epoch [9300/20000], Loss: 0.0626\n",
      "Epoch [9400/20000], Loss: 0.0621\n",
      "Epoch [9500/20000], Loss: 0.0616\n",
      "Epoch [9600/20000], Loss: 0.0610\n",
      "Epoch [9700/20000], Loss: 0.0605\n",
      "Epoch [9800/20000], Loss: 0.0600\n",
      "Epoch [9900/20000], Loss: 0.0595\n",
      "Epoch [10000/20000], Loss: 0.0590\n",
      "Epoch [10100/20000], Loss: 0.0586\n",
      "Epoch [10200/20000], Loss: 0.0581\n",
      "Epoch [10300/20000], Loss: 0.0576\n",
      "Epoch [10400/20000], Loss: 0.0572\n",
      "Epoch [10500/20000], Loss: 0.0567\n",
      "Epoch [10600/20000], Loss: 0.0563\n",
      "Epoch [10700/20000], Loss: 0.0558\n",
      "Epoch [10800/20000], Loss: 0.0554\n",
      "Epoch [10900/20000], Loss: 0.0550\n",
      "Epoch [11000/20000], Loss: 0.0546\n",
      "Epoch [11100/20000], Loss: 0.0541\n",
      "Epoch [11200/20000], Loss: 0.0537\n",
      "Epoch [11300/20000], Loss: 0.0533\n",
      "Epoch [11400/20000], Loss: 0.0530\n",
      "Epoch [11500/20000], Loss: 0.0526\n",
      "Epoch [11600/20000], Loss: 0.0522\n",
      "Epoch [11700/20000], Loss: 0.0518\n",
      "Epoch [11800/20000], Loss: 0.0514\n",
      "Epoch [11900/20000], Loss: 0.0511\n",
      "Epoch [12000/20000], Loss: 0.0507\n",
      "Epoch [12100/20000], Loss: 0.0504\n",
      "Epoch [12200/20000], Loss: 0.0500\n",
      "Epoch [12300/20000], Loss: 0.0497\n",
      "Epoch [12400/20000], Loss: 0.0493\n",
      "Epoch [12500/20000], Loss: 0.0490\n",
      "Epoch [12600/20000], Loss: 0.0487\n",
      "Epoch [12700/20000], Loss: 0.0484\n",
      "Epoch [12800/20000], Loss: 0.0480\n",
      "Epoch [12900/20000], Loss: 0.0477\n",
      "Epoch [13000/20000], Loss: 0.0474\n",
      "Epoch [13100/20000], Loss: 0.0471\n",
      "Epoch [13200/20000], Loss: 0.0468\n",
      "Epoch [13300/20000], Loss: 0.0465\n",
      "Epoch [13400/20000], Loss: 0.0462\n",
      "Epoch [13500/20000], Loss: 0.0459\n",
      "Epoch [13600/20000], Loss: 0.0456\n",
      "Epoch [13700/20000], Loss: 0.0453\n",
      "Epoch [13800/20000], Loss: 0.0450\n",
      "Epoch [13900/20000], Loss: 0.0448\n",
      "Epoch [14000/20000], Loss: 0.0445\n",
      "Epoch [14100/20000], Loss: 0.0442\n",
      "Epoch [14200/20000], Loss: 0.0440\n",
      "Epoch [14300/20000], Loss: 0.0437\n",
      "Epoch [14400/20000], Loss: 0.0434\n",
      "Epoch [14500/20000], Loss: 0.0432\n",
      "Epoch [14600/20000], Loss: 0.0429\n",
      "Epoch [14700/20000], Loss: 0.0427\n",
      "Epoch [14800/20000], Loss: 0.0424\n",
      "Epoch [14900/20000], Loss: 0.0422\n",
      "Epoch [15000/20000], Loss: 0.0419\n",
      "Epoch [15100/20000], Loss: 0.0417\n",
      "Epoch [15200/20000], Loss: 0.0414\n",
      "Epoch [15300/20000], Loss: 0.0412\n",
      "Epoch [15400/20000], Loss: 0.0410\n",
      "Epoch [15500/20000], Loss: 0.0407\n",
      "Epoch [15600/20000], Loss: 0.0405\n",
      "Epoch [15700/20000], Loss: 0.0403\n",
      "Epoch [15800/20000], Loss: 0.0401\n",
      "Epoch [15900/20000], Loss: 0.0399\n",
      "Epoch [16000/20000], Loss: 0.0396\n",
      "Epoch [16100/20000], Loss: 0.0394\n",
      "Epoch [16200/20000], Loss: 0.0392\n",
      "Epoch [16300/20000], Loss: 0.0390\n",
      "Epoch [16400/20000], Loss: 0.0388\n",
      "Epoch [16500/20000], Loss: 0.0386\n",
      "Epoch [16600/20000], Loss: 0.0384\n",
      "Epoch [16700/20000], Loss: 0.0382\n",
      "Epoch [16800/20000], Loss: 0.0380\n",
      "Epoch [16900/20000], Loss: 0.0378\n",
      "Epoch [17000/20000], Loss: 0.0376\n",
      "Epoch [17100/20000], Loss: 0.0374\n",
      "Epoch [17200/20000], Loss: 0.0372\n",
      "Epoch [17300/20000], Loss: 0.0370\n",
      "Epoch [17400/20000], Loss: 0.0368\n",
      "Epoch [17500/20000], Loss: 0.0366\n",
      "Epoch [17600/20000], Loss: 0.0365\n",
      "Epoch [17700/20000], Loss: 0.0363\n",
      "Epoch [17800/20000], Loss: 0.0361\n",
      "Epoch [17900/20000], Loss: 0.0359\n",
      "Epoch [18000/20000], Loss: 0.0357\n",
      "Epoch [18100/20000], Loss: 0.0356\n",
      "Epoch [18200/20000], Loss: 0.0354\n",
      "Epoch [18300/20000], Loss: 0.0352\n",
      "Epoch [18400/20000], Loss: 0.0351\n",
      "Epoch [18500/20000], Loss: 0.0349\n",
      "Epoch [18600/20000], Loss: 0.0347\n",
      "Epoch [18700/20000], Loss: 0.0346\n",
      "Epoch [18800/20000], Loss: 0.0344\n",
      "Epoch [18900/20000], Loss: 0.0342\n",
      "Epoch [19000/20000], Loss: 0.0341\n",
      "Epoch [19100/20000], Loss: 0.0339\n",
      "Epoch [19200/20000], Loss: 0.0338\n",
      "Epoch [19300/20000], Loss: 0.0336\n",
      "Epoch [19400/20000], Loss: 0.0335\n",
      "Epoch [19500/20000], Loss: 0.0333\n",
      "Epoch [19600/20000], Loss: 0.0332\n",
      "Epoch [19700/20000], Loss: 0.0330\n",
      "Epoch [19800/20000], Loss: 0.0329\n",
      "Epoch [19900/20000], Loss: 0.0327\n",
      "Epoch [20000/20000], Loss: 0.0326\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "h = np.array([10, 7, 5, 4])\n",
    "s = np.array([1, 1, 0, 0])\n",
    "hours = torch.FloatTensor(h).view(-1,1)\n",
    "score = torch.FloatTensor(s).view(-1,1)\n",
    "num_epochs = 20000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(hours)\n",
    "    loss = criterion(outputs, score)\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a16f2d1-277c-4454-a306-af16774d4b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "plt.plot(h, s, 'o')\n",
    "x = torch.linspace(0, 10, 100)\n",
    "predict = model(x.view(-1,1))\n",
    "predict = predict.detach().numpy()\n",
    "plt.plot(x.numpy(), predict, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b3641-af7a-4d6f-92fb-c3d641d31993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c995808c-318c-47ab-b342-b0938b2064e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## F 공부하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f2c4663-9f03-4a5d-a540-16e794e5a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class XOR_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XOR_Model, self).__init__()\n",
    "        self.l1 = nn.Linear(2, 8)\n",
    "        self.l2 = nn.Linear(8, 4)\n",
    "        self.l3 = nn.Linear(4, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.activation(self.l2(out))\n",
    "        out = F.sigmoid(self.l3(out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = XOR_Model() ## 두번쨰 forward 실행 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f97a3d7-61e1-4648-951c-c1214afe7ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/20000], Loss: 0.6931\n",
      "Epoch [200/20000], Loss: 0.6931\n",
      "Epoch [300/20000], Loss: 0.6931\n",
      "Epoch [400/20000], Loss: 0.6931\n",
      "Epoch [500/20000], Loss: 0.6931\n",
      "Epoch [600/20000], Loss: 0.6931\n",
      "Epoch [700/20000], Loss: 0.6931\n",
      "Epoch [800/20000], Loss: 0.6931\n",
      "Epoch [900/20000], Loss: 0.6931\n",
      "Epoch [1000/20000], Loss: 0.6931\n",
      "Epoch [1100/20000], Loss: 0.6931\n",
      "Epoch [1200/20000], Loss: 0.6930\n",
      "Epoch [1300/20000], Loss: 0.6930\n",
      "Epoch [1400/20000], Loss: 0.6930\n",
      "Epoch [1500/20000], Loss: 0.6930\n",
      "Epoch [1600/20000], Loss: 0.6930\n",
      "Epoch [1700/20000], Loss: 0.6930\n",
      "Epoch [1800/20000], Loss: 0.6930\n",
      "Epoch [1900/20000], Loss: 0.6930\n",
      "Epoch [2000/20000], Loss: 0.6930\n",
      "Epoch [2100/20000], Loss: 0.6930\n",
      "Epoch [2200/20000], Loss: 0.6930\n",
      "Epoch [2300/20000], Loss: 0.6930\n",
      "Epoch [2400/20000], Loss: 0.6929\n",
      "Epoch [2500/20000], Loss: 0.6929\n",
      "Epoch [2600/20000], Loss: 0.6929\n",
      "Epoch [2700/20000], Loss: 0.6929\n",
      "Epoch [2800/20000], Loss: 0.6929\n",
      "Epoch [2900/20000], Loss: 0.6929\n",
      "Epoch [3000/20000], Loss: 0.6929\n",
      "Epoch [3100/20000], Loss: 0.6929\n",
      "Epoch [3200/20000], Loss: 0.6929\n",
      "Epoch [3300/20000], Loss: 0.6928\n",
      "Epoch [3400/20000], Loss: 0.6928\n",
      "Epoch [3500/20000], Loss: 0.6928\n",
      "Epoch [3600/20000], Loss: 0.6928\n",
      "Epoch [3700/20000], Loss: 0.6928\n",
      "Epoch [3800/20000], Loss: 0.6928\n",
      "Epoch [3900/20000], Loss: 0.6928\n",
      "Epoch [4000/20000], Loss: 0.6928\n",
      "Epoch [4100/20000], Loss: 0.6927\n",
      "Epoch [4200/20000], Loss: 0.6927\n",
      "Epoch [4300/20000], Loss: 0.6927\n",
      "Epoch [4400/20000], Loss: 0.6927\n",
      "Epoch [4500/20000], Loss: 0.6927\n",
      "Epoch [4600/20000], Loss: 0.6926\n",
      "Epoch [4700/20000], Loss: 0.6926\n",
      "Epoch [4800/20000], Loss: 0.6926\n",
      "Epoch [4900/20000], Loss: 0.6926\n",
      "Epoch [5000/20000], Loss: 0.6926\n",
      "Epoch [5100/20000], Loss: 0.6925\n",
      "Epoch [5200/20000], Loss: 0.6925\n",
      "Epoch [5300/20000], Loss: 0.6925\n",
      "Epoch [5400/20000], Loss: 0.6924\n",
      "Epoch [5500/20000], Loss: 0.6924\n",
      "Epoch [5600/20000], Loss: 0.6924\n",
      "Epoch [5700/20000], Loss: 0.6923\n",
      "Epoch [5800/20000], Loss: 0.6923\n",
      "Epoch [5900/20000], Loss: 0.6923\n",
      "Epoch [6000/20000], Loss: 0.6922\n",
      "Epoch [6100/20000], Loss: 0.6922\n",
      "Epoch [6200/20000], Loss: 0.6921\n",
      "Epoch [6300/20000], Loss: 0.6921\n",
      "Epoch [6400/20000], Loss: 0.6920\n",
      "Epoch [6500/20000], Loss: 0.6920\n",
      "Epoch [6600/20000], Loss: 0.6919\n",
      "Epoch [6700/20000], Loss: 0.6918\n",
      "Epoch [6800/20000], Loss: 0.6918\n",
      "Epoch [6900/20000], Loss: 0.6917\n",
      "Epoch [7000/20000], Loss: 0.6916\n",
      "Epoch [7100/20000], Loss: 0.6915\n",
      "Epoch [7200/20000], Loss: 0.6914\n",
      "Epoch [7300/20000], Loss: 0.6913\n",
      "Epoch [7400/20000], Loss: 0.6912\n",
      "Epoch [7500/20000], Loss: 0.6910\n",
      "Epoch [7600/20000], Loss: 0.6909\n",
      "Epoch [7700/20000], Loss: 0.6907\n",
      "Epoch [7800/20000], Loss: 0.6905\n",
      "Epoch [7900/20000], Loss: 0.6903\n",
      "Epoch [8000/20000], Loss: 0.6901\n",
      "Epoch [8100/20000], Loss: 0.6898\n",
      "Epoch [8200/20000], Loss: 0.6895\n",
      "Epoch [8300/20000], Loss: 0.6892\n",
      "Epoch [8400/20000], Loss: 0.6888\n",
      "Epoch [8500/20000], Loss: 0.6884\n",
      "Epoch [8600/20000], Loss: 0.6879\n",
      "Epoch [8700/20000], Loss: 0.6873\n",
      "Epoch [8800/20000], Loss: 0.6867\n",
      "Epoch [8900/20000], Loss: 0.6859\n",
      "Epoch [9000/20000], Loss: 0.6850\n",
      "Epoch [9100/20000], Loss: 0.6839\n",
      "Epoch [9200/20000], Loss: 0.6825\n",
      "Epoch [9300/20000], Loss: 0.6809\n",
      "Epoch [9400/20000], Loss: 0.6788\n",
      "Epoch [9500/20000], Loss: 0.6763\n",
      "Epoch [9600/20000], Loss: 0.6731\n",
      "Epoch [9700/20000], Loss: 0.6689\n",
      "Epoch [9800/20000], Loss: 0.6634\n",
      "Epoch [9900/20000], Loss: 0.6560\n",
      "Epoch [10000/20000], Loss: 0.6459\n",
      "Epoch [10100/20000], Loss: 0.6318\n",
      "Epoch [10200/20000], Loss: 0.6115\n",
      "Epoch [10300/20000], Loss: 0.5822\n",
      "Epoch [10400/20000], Loss: 0.5396\n",
      "Epoch [10500/20000], Loss: 0.4799\n",
      "Epoch [10600/20000], Loss: 0.4026\n",
      "Epoch [10700/20000], Loss: 0.3164\n",
      "Epoch [10800/20000], Loss: 0.2365\n",
      "Epoch [10900/20000], Loss: 0.1735\n",
      "Epoch [11000/20000], Loss: 0.1287\n",
      "Epoch [11100/20000], Loss: 0.0979\n",
      "Epoch [11200/20000], Loss: 0.0768\n",
      "Epoch [11300/20000], Loss: 0.0619\n",
      "Epoch [11400/20000], Loss: 0.0511\n",
      "Epoch [11500/20000], Loss: 0.0431\n",
      "Epoch [11600/20000], Loss: 0.0370\n",
      "Epoch [11700/20000], Loss: 0.0322\n",
      "Epoch [11800/20000], Loss: 0.0284\n",
      "Epoch [11900/20000], Loss: 0.0253\n",
      "Epoch [12000/20000], Loss: 0.0228\n",
      "Epoch [12100/20000], Loss: 0.0206\n",
      "Epoch [12200/20000], Loss: 0.0188\n",
      "Epoch [12300/20000], Loss: 0.0173\n",
      "Epoch [12400/20000], Loss: 0.0160\n",
      "Epoch [12500/20000], Loss: 0.0148\n",
      "Epoch [12600/20000], Loss: 0.0138\n",
      "Epoch [12700/20000], Loss: 0.0129\n",
      "Epoch [12800/20000], Loss: 0.0121\n",
      "Epoch [12900/20000], Loss: 0.0114\n",
      "Epoch [13000/20000], Loss: 0.0108\n",
      "Epoch [13100/20000], Loss: 0.0102\n",
      "Epoch [13200/20000], Loss: 0.0097\n",
      "Epoch [13300/20000], Loss: 0.0092\n",
      "Epoch [13400/20000], Loss: 0.0088\n",
      "Epoch [13500/20000], Loss: 0.0084\n",
      "Epoch [13600/20000], Loss: 0.0080\n",
      "Epoch [13700/20000], Loss: 0.0077\n",
      "Epoch [13800/20000], Loss: 0.0074\n",
      "Epoch [13900/20000], Loss: 0.0071\n",
      "Epoch [14000/20000], Loss: 0.0068\n",
      "Epoch [14100/20000], Loss: 0.0065\n",
      "Epoch [14200/20000], Loss: 0.0063\n",
      "Epoch [14300/20000], Loss: 0.0061\n",
      "Epoch [14400/20000], Loss: 0.0059\n",
      "Epoch [14500/20000], Loss: 0.0057\n",
      "Epoch [14600/20000], Loss: 0.0055\n",
      "Epoch [14700/20000], Loss: 0.0053\n",
      "Epoch [14800/20000], Loss: 0.0052\n",
      "Epoch [14900/20000], Loss: 0.0050\n",
      "Epoch [15000/20000], Loss: 0.0049\n",
      "Epoch [15100/20000], Loss: 0.0048\n",
      "Epoch [15200/20000], Loss: 0.0046\n",
      "Epoch [15300/20000], Loss: 0.0045\n",
      "Epoch [15400/20000], Loss: 0.0044\n",
      "Epoch [15500/20000], Loss: 0.0043\n",
      "Epoch [15600/20000], Loss: 0.0042\n",
      "Epoch [15700/20000], Loss: 0.0041\n",
      "Epoch [15800/20000], Loss: 0.0040\n",
      "Epoch [15900/20000], Loss: 0.0039\n",
      "Epoch [16000/20000], Loss: 0.0038\n",
      "Epoch [16100/20000], Loss: 0.0037\n",
      "Epoch [16200/20000], Loss: 0.0036\n",
      "Epoch [16300/20000], Loss: 0.0035\n",
      "Epoch [16400/20000], Loss: 0.0035\n",
      "Epoch [16500/20000], Loss: 0.0034\n",
      "Epoch [16600/20000], Loss: 0.0033\n",
      "Epoch [16700/20000], Loss: 0.0033\n",
      "Epoch [16800/20000], Loss: 0.0032\n",
      "Epoch [16900/20000], Loss: 0.0031\n",
      "Epoch [17000/20000], Loss: 0.0031\n",
      "Epoch [17100/20000], Loss: 0.0030\n",
      "Epoch [17200/20000], Loss: 0.0030\n",
      "Epoch [17300/20000], Loss: 0.0029\n",
      "Epoch [17400/20000], Loss: 0.0029\n",
      "Epoch [17500/20000], Loss: 0.0028\n",
      "Epoch [17600/20000], Loss: 0.0028\n",
      "Epoch [17700/20000], Loss: 0.0027\n",
      "Epoch [17800/20000], Loss: 0.0027\n",
      "Epoch [17900/20000], Loss: 0.0026\n",
      "Epoch [18000/20000], Loss: 0.0026\n",
      "Epoch [18100/20000], Loss: 0.0025\n",
      "Epoch [18200/20000], Loss: 0.0025\n",
      "Epoch [18300/20000], Loss: 0.0025\n",
      "Epoch [18400/20000], Loss: 0.0024\n",
      "Epoch [18500/20000], Loss: 0.0024\n",
      "Epoch [18600/20000], Loss: 0.0023\n",
      "Epoch [18700/20000], Loss: 0.0023\n",
      "Epoch [18800/20000], Loss: 0.0023\n",
      "Epoch [18900/20000], Loss: 0.0022\n",
      "Epoch [19000/20000], Loss: 0.0022\n",
      "Epoch [19100/20000], Loss: 0.0022\n",
      "Epoch [19200/20000], Loss: 0.0021\n",
      "Epoch [19300/20000], Loss: 0.0021\n",
      "Epoch [19400/20000], Loss: 0.0021\n",
      "Epoch [19500/20000], Loss: 0.0021\n",
      "Epoch [19600/20000], Loss: 0.0020\n",
      "Epoch [19700/20000], Loss: 0.0020\n",
      "Epoch [19800/20000], Loss: 0.0020\n",
      "Epoch [19900/20000], Loss: 0.0020\n",
      "Epoch [20000/20000], Loss: 0.0019\n",
      "tensor([[0.0016],\n",
      "        [0.9978],\n",
      "        [0.9983],\n",
      "        [0.0023]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "x = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "x_t = torch.FloatTensor(x).view(x.shape[0],-1)\n",
    "y_t = torch.FloatTensor(y).view(x.shape[0],1)\n",
    "\n",
    "\n",
    "num_epochs = 20000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(x_t)\n",
    "    loss = criterion(outputs, y_t)\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "predict = model(x_t)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "17cc19eb-7aa4-4927-8256-6ac9573cbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                    [93, 88, 93],\n",
    "                    [89, 91, 90],\n",
    "                    [96, 98, 100],\n",
    "                    [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1124d651-a688-46cb-bff3-a86ed4051ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[73., 66., 70.],\n",
      "        [73., 80., 75.]])\n",
      "torch.Size([2, 1])\n",
      "tensor([[142.],\n",
      "        [152.]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=2,\n",
    "                        shuffle=True)\n",
    "data,label= next(iter(dataloader))\n",
    "print(data.shape)\n",
    "print(data)\n",
    "\n",
    "print(label.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1b3e1bfd-1a59-4446-ba0c-1b4375f913a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6ab78b1a-46b5-48c9-bd64-74a0c12c9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "be389f23-e115-4939-843a-e9e28c1119b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int64\n",
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# 입력 -> 1by4\n",
    "print(X.dtype)\n",
    "print(y.dtype)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "41031174-bd94-45fd-a31c-96478f2e837f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1c7b9717-e7cb-4602-8d55-f8c0ac065fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "04cee7ed-532d-4f77-8681-7b214b7139b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n",
      "(120,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "898ddebc-d9b6-46c9-a450-01ad284bd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype = torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c12144a5-3c42-4d85-815c-93f39981e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7a27cfe6-e189-4855-8ff4-464a36b25137",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in, y_out = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f48bcb51-ce6f-4fd4-9c5f-7d08e53efad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(x_in.shape)\n",
    "print(y_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d5cb660e-4a8c-4b04-acd2-660453de339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class myModel(nn.Module): ## nn.모델 상속\n",
    "    def __init__(self):\n",
    "        super(myModel, self).__init__() ## 상속 받은 거 초기화\n",
    "        self.fc1 = nn.Linear(4, 100)    ## 입력의 크기 4, 아웃풋 100개\n",
    "        self.fc2 = nn.Linear(100, 3)    ## 출력받은 100개를 입력으로 넣고 3개로 출력\n",
    "        # self.act = nn.Sigmoid() \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x)) ## 활성화 함수  미리 정하지 않았는데 쓰고  싶은 경우\n",
    "        # self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # x = F.softmax.fc2(x) 이렇게 불가능함 \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d9bd4820-f054-4d4d-babe-be602620c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myModel(\n",
      "  (fc1): Linear(in_features=4, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = myModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e3db018e-75a1-43fc-a73e-2914354eaa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]             500\n",
      "            Linear-2                 [-1, 1, 3]             303\n",
      "================================================================\n",
      "Total params: 803\n",
      "Trainable params: 803\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = myModel()\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, (1,4), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b66a42ca-f8ad-48ca-ab48-9d43be29421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  ## softmax 함수가 구현되어져 있음 함수짤때 생각\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b6c441e1-116d-43d1-98d6-5d109fd675a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.0768057107925415\n",
      "Epoch 20, Loss: 1.0456739664077759\n",
      "Epoch 30, Loss: 1.053147315979004\n",
      "Epoch 40, Loss: 1.0311355590820312\n",
      "Epoch 50, Loss: 1.0503257513046265\n",
      "Epoch 60, Loss: 1.0057786703109741\n",
      "Epoch 70, Loss: 0.9998794198036194\n",
      "Epoch 80, Loss: 0.9615100622177124\n",
      "Epoch 90, Loss: 0.9752808809280396\n",
      "Epoch 100, Loss: 0.9790101647377014\n",
      "Epoch 110, Loss: 0.9337720274925232\n",
      "Epoch 120, Loss: 0.9201556444168091\n",
      "Epoch 130, Loss: 0.9183594584465027\n",
      "Epoch 140, Loss: 0.9998905062675476\n",
      "Epoch 150, Loss: 0.8582054972648621\n",
      "Epoch 160, Loss: 0.8899263143539429\n",
      "Epoch 170, Loss: 0.8471554517745972\n",
      "Epoch 180, Loss: 0.8247213363647461\n",
      "Epoch 190, Loss: 0.9202734231948853\n",
      "Epoch 200, Loss: 0.9115082621574402\n",
      "Epoch 210, Loss: 0.7493004202842712\n",
      "Epoch 220, Loss: 0.8548351526260376\n",
      "Epoch 230, Loss: 0.7276009321212769\n",
      "Epoch 240, Loss: 0.7293468117713928\n",
      "Epoch 250, Loss: 0.8916587829589844\n",
      "Epoch 260, Loss: 0.750939130783081\n",
      "Epoch 270, Loss: 0.779137134552002\n",
      "Epoch 280, Loss: 0.8713021874427795\n",
      "Epoch 290, Loss: 0.8112769722938538\n",
      "Epoch 300, Loss: 0.8319821357727051\n",
      "Epoch 310, Loss: 0.7172941565513611\n",
      "Epoch 320, Loss: 0.7983435988426208\n",
      "Epoch 330, Loss: 0.7409720420837402\n",
      "Epoch 340, Loss: 0.6403608918190002\n",
      "Epoch 350, Loss: 0.7649435997009277\n",
      "Epoch 360, Loss: 0.6583598852157593\n",
      "Epoch 370, Loss: 0.7385545969009399\n",
      "Epoch 380, Loss: 0.7292559146881104\n",
      "Epoch 390, Loss: 0.838874101638794\n",
      "Epoch 400, Loss: 0.8016378283500671\n",
      "Epoch 410, Loss: 0.7278833389282227\n",
      "Epoch 420, Loss: 0.6298618912696838\n",
      "Epoch 430, Loss: 0.6089254021644592\n",
      "Epoch 440, Loss: 0.6246832609176636\n",
      "Epoch 450, Loss: 0.7087724804878235\n",
      "Epoch 460, Loss: 0.7070645689964294\n",
      "Epoch 470, Loss: 0.6092789173126221\n",
      "Epoch 480, Loss: 0.6805940866470337\n",
      "Epoch 490, Loss: 0.6785170435905457\n",
      "Epoch 500, Loss: 0.7162804007530212\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e2bbb540-b6eb-4f8a-b0bd-4cf7556f2b95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3570.38it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3517.97it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3676.39it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3527.22it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3262.46it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3108.04it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2134.51it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3501.09it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 1784.24it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2371.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.6947660446166992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2463.61it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2846.01it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3339.08it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2451.73it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2647.29it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2655.04it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2554.97it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2510.24it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2402.58it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2613.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.6143776774406433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2020.13it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2545.47it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2217.30it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2870.60it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2346.79it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2534.90it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2395.03it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2596.49it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2558.28it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2354.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.7531804442405701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2457.84it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2586.48it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2818.99it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2583.10it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2934.62it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2776.77it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3049.85it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2531.84it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3073.31it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2832.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.6068188548088074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2517.40it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2581.31it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2749.01it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3035.23it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2673.02it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3116.41it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3203.59it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3079.52it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2959.73it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2392.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.5703808069229126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3013.15it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3301.63it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2818.75it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2291.50it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2717.40it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2186.38it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2771.03it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2427.26it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2610.02it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3053.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss: 0.4912736117839813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2639.38it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2966.27it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2705.57it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2594.28it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3140.92it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2860.32it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2664.95it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2621.24it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3038.25it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3175.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Loss: 0.6158742904663086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2735.12it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2569.06it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2963.13it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2689.09it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2661.36it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2911.19it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2496.24it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3138.27it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2508.74it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2867.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Loss: 0.707990825176239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2641.25it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3023.74it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2659.46it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2780.91it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2882.19it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2923.88it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3024.56it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2456.22it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3038.25it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2416.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss: 0.5508973598480225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2744.29it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2312.82it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2979.70it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3152.13it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3018.84it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2906.91it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2255.31it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2938.99it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 2288.22it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 3031.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.488571435213089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X_batch, y_batch) in enumerate(tqdm(train_loader)): ## 사진 참고하기\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d6c956ab-7acf-48d0-9a31-2a16f9a863a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auccuracy: 90.0%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    print(f'Auccuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d298401-976d-433f-ae0a-e910de4f5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cf771-2b60-4d51-ad86-990ad6bfbf41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3dce3-dcd5-439b-9283-7fb76797baed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc68bf1-741a-45af-851e-e6f200f6cd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44849ca3-8a53-4f8d-a97a-6a836072f4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26869a8-86d2-49af-9afa-99f7c0af3f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
